{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "from itertools import cycle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = {\n",
    "    # ResNet\n",
    "    'ResNet': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "\n",
    "    # EfficientNet_b1\n",
    "    'EfficientNet': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(240),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40474</th>\n",
       "      <td>train_40474</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40475</th>\n",
       "      <td>train_40475</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40476</th>\n",
       "      <td>train_40476</td>\n",
       "      <td>agriculture clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40477</th>\n",
       "      <td>train_40477</td>\n",
       "      <td>agriculture clear primary road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40478</th>\n",
       "      <td>train_40478</td>\n",
       "      <td>agriculture cultivation partly_cloudy primary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40479 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name                                           tags\n",
       "0          train_0                                   haze primary\n",
       "1          train_1                agriculture clear primary water\n",
       "2          train_2                                  clear primary\n",
       "3          train_3                                  clear primary\n",
       "4          train_4      agriculture clear habitation primary road\n",
       "...            ...                                            ...\n",
       "40474  train_40474                                  clear primary\n",
       "40475  train_40475                                         cloudy\n",
       "40476  train_40476                      agriculture clear primary\n",
       "40477  train_40477                 agriculture clear primary road\n",
       "40478  train_40478  agriculture cultivation partly_cloudy primary\n",
       "\n",
       "[40479 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_classes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = set()\n",
    "for tags in df['tags'].str.split():\n",
    "    all_tags.update(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agriculture': 0, 'artisinal_mine': 1, 'bare_ground': 2, 'blooming': 3, 'blow_down': 4, 'clear': 5, 'cloudy': 6, 'conventional_mine': 7, 'cultivation': 8, 'habitation': 9, 'haze': 10, 'partly_cloudy': 11, 'primary': 12, 'road': 13, 'selective_logging': 14, 'slash_burn': 15, 'water': 16}\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "tag_to_idx = {tag: idx for idx, tag in enumerate(sorted(all_tags))}\n",
    "idx_to_tag = {idx: tag for tag, idx in tag_to_idx.items()}\n",
    "print(tag_to_idx)\n",
    "print(len(tag_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, f\"{img_name}.jpg\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        tags = self.df.iloc[idx, 1].split()\n",
    "        labels = torch.zeros(len(tag_to_idx))\n",
    "        for tag in tags:\n",
    "            labels[tag_to_idx[tag]] = 1\n",
    "        \n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_dataset = MultiLabelImageDataset(csv_file=\"data/train_classes.csv\", img_dir=\"data/train-jpg\", transform=transforms['ResNet'])\n",
    "effnet_dataset = MultiLabelImageDataset(csv_file=\"data/train_classes.csv\", img_dir=\"data/train-jpg\", transform=transforms['ResNet'])\n",
    "resnet2_dataset = MultiLabelImageDataset(csv_file=\"data/train_classes.csv\", img_dir=\"data/train-jpg\", transform=transforms['ResNet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_idx, test_idx):\n",
    "    train_dataset = Subset(dataset, train_idx)\n",
    "    test_dataset = Subset(dataset, test_idx)\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "dataset_length = len(resnet_dataset)\n",
    "train_idx, test_idx = train_test_split(\n",
    "    list(range(dataset_length)), \n",
    "    test_size=0.1, \n",
    "    # random_state=42\n",
    ")\n",
    "\n",
    "resnet_train, resnet_test = split_dataset(resnet_dataset, train_idx, test_idx)\n",
    "effnet_train, effnet_test = split_dataset(effnet_dataset, train_idx, test_idx)\n",
    "resnet2_train, resnet2_test = split_dataset(resnet2_dataset, train_idx, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "resnet_train_loader = DataLoader(resnet_train, batch_size=batch_size, shuffle=True)\n",
    "resnet_test_loader = DataLoader(resnet_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "effnet_train_loader = DataLoader(effnet_train, batch_size=batch_size, shuffle=True)\n",
    "effnet_test_loader = DataLoader(effnet_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "resnet2_train_loader = DataLoader(resnet2_train, batch_size=batch_size, shuffle=True)\n",
    "resnet2_test_loader = DataLoader(resnet2_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torch import nn\n",
    "\n",
    "num_classes = 17\n",
    "\n",
    "def ResNetClassifier(num_classes):  \n",
    "    # load a pre-trained model\n",
    "    model_ft = models.resnet50(weights='DEFAULT')\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    \n",
    "    # freeze all the parameters in the network except the final layer\n",
    "    # for param in model_ft.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    \n",
    "    # replace the last fully connected layer\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model_ft\n",
    "\n",
    "def EfficientNetClassifier(num_classes):\n",
    "    # load a pre-trained model\n",
    "    model_ft = models.efficientnet_b1(weights='DEFAULT')\n",
    "    num_ftrs = model_ft.classifier[1].in_features\n",
    "    \n",
    "    # freeze all the parameters in the network except the final layer\n",
    "    # for param in model_ft.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    \n",
    "    # replace the last fully connected layer\n",
    "    model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, num_classes, ensemble_type='weighted'):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        \n",
    "        # initialize individual models\n",
    "        self.resnet = ResNetClassifier(num_classes)\n",
    "        self.effnet = ResNetClassifier(num_classes)\n",
    "        self.resnet2 = ResNetClassifier(num_classes)\n",
    "\n",
    "        self.resnet.load_state_dict(torch.load(\"LP_oversampled_ResNet50_0.5epochs_1e-4_ADAM.pth\", weights_only=True))\n",
    "        self.effnet.load_state_dict(torch.load(\"ML_oversampled_augmented_ResNet50_5epochs_1e-4_ADAM.pth\", weights_only=True))\n",
    "        self.resnet2.load_state_dict(torch.load(\"LP_oversampled_ResNet50_0.5epochs_1e-4_ADAM.pth\", weights_only=True))\n",
    "        \n",
    "        # ensemble type\n",
    "        self.ensemble_type = ensemble_type\n",
    "        \n",
    "        # weighted averaging - initialised to 1/3 each\n",
    "        if ensemble_type == 'weighted':\n",
    "            self.weights = nn.Parameter(torch.ones(3) / 3)\n",
    "\n",
    "        # parameters for shepard's rule\n",
    "        self.a = 1.0\n",
    "        self.b = 1.0\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # get predictions from each model\n",
    "        resnet_out = self.resnet(x)\n",
    "        effnet_out = self.effnet(x)\n",
    "        resnet2_out = self.resnet2(x)\n",
    "        \n",
    "        # ensemble strategies\n",
    "        if self.ensemble_type == 'voting':\n",
    "            # soft voting - average of predictions\n",
    "            return (resnet_out + effnet_out + resnet2_out) / 3\n",
    "        \n",
    "        elif self.ensemble_type == 'weighted':\n",
    "            # weighted average of predictions\n",
    "            # normalize weights to sum to 1\n",
    "            normalized_weights = nn.functional.softmax(self.weights, dim=0)\n",
    "            \n",
    "            weighted_out = (\n",
    "                normalized_weights[0] * resnet_out + \n",
    "                normalized_weights[1] * effnet_out + \n",
    "                normalized_weights[2] * resnet2_out\n",
    "            )\n",
    "            return weighted_out\n",
    "\n",
    "        elif self.ensemble_type == 'dudani':\n",
    "            # dudani's rule weights\n",
    "            distances = torch.stack([\n",
    "                -torch.max(torch.sigmoid(resnet_out), dim=1)[0],\n",
    "                -torch.max(torch.sigmoid(effnet_out), dim=1)[0],\n",
    "                -torch.max(torch.sigmoid(resnet2_out), dim=1)[0]\n",
    "            ], dim=1) \n",
    "            \n",
    "            d1, _ = torch.min(distances, dim=1, keepdim=True)\n",
    "            dq, _ = torch.max(distances, dim=1, keepdim=True)\n",
    "            \n",
    "            diff = dq - d1\n",
    "            diff[diff == 0] = 1e-10\n",
    "            \n",
    "            dudani_weights = (dq - distances) / diff\n",
    "            dudani_weights = dudani_weights / dudani_weights.sum(dim=1, keepdim=True)\n",
    "\n",
    "            weighted_out = (\n",
    "                dudani_weights[:, 0].unsqueeze(1) * resnet_out +\n",
    "                dudani_weights[:, 1].unsqueeze(1) * effnet_out +\n",
    "                dudani_weights[:, 2].unsqueeze(1) * resnet2_out\n",
    "            )\n",
    "            return weighted_out\n",
    "\n",
    "        elif self.ensemble_type == 'shepard':\n",
    "            distances = torch.stack([\n",
    "                -torch.max(torch.sigmoid(resnet_out), dim=1)[0],\n",
    "                -torch.max(torch.sigmoid(effnet_out), dim=1)[0],\n",
    "                -torch.max(torch.sigmoid(resnet2_out), dim=1)[0]\n",
    "            ], dim=1)\n",
    "\n",
    "            shepard_weights = torch.exp(-self.a * torch.abs(distances) ** self.b)\n",
    "            shepard_weights = shepard_weights / shepard_weights.sum(dim=1, keepdim=True)\n",
    "\n",
    "            weighted_out = (\n",
    "                shepard_weights[:, 0].unsqueeze(1) * resnet_out +\n",
    "                shepard_weights[:, 1].unsqueeze(1) * effnet_out +\n",
    "                shepard_weights[:, 2].unsqueeze(1) * resnet2_out\n",
    "            )\n",
    "            return weighted_out\n",
    "        \n",
    "        else:\n",
    "            return (resnet_out + effnet_out + resnet2_out) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble_model(\n",
    "    resnet_train_loader, \n",
    "    effnet_train_loader,\n",
    "    resnet2_train_loader,\n",
    "    resnet_test_loader, \n",
    "    effnet_test_loader,\n",
    "    resnet2_test_loader,\n",
    "    num_classes, \n",
    "    epochs, \n",
    "    learning_rate, \n",
    "    threshold,\n",
    "    ensemble_type) :\n",
    "\n",
    "    model = EnsembleModel(num_classes, ensemble_type).to(device)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.75)\n",
    "    \n",
    "    # training loop\n",
    "    all_loss = []\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        \n",
    "        dataloaders = [resnet_train_loader, effnet_train_loader, resnet2_train_loader]\n",
    "        max_loader_len = max(len(loader) for loader in dataloaders)\n",
    "        \n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_idx in range(max_loader_len):\n",
    "            # cycle through dataloaders\n",
    "            X_resnet, y_resnet = next(cycle(resnet_train_loader))\n",
    "            X_effnet, y_effnet = next(cycle(effnet_train_loader))\n",
    "            X_resnet2, y_resnet2 = next(cycle(resnet2_train_loader))\n",
    "            \n",
    "            X_resnet = X_resnet.to(device)\n",
    "            X_effnet = X_effnet.to(device)\n",
    "            X_resnet2 = X_resnet2.to(device)\n",
    "            \n",
    "            y_resnet = y_resnet.to(device)\n",
    "            y_effnet = y_effnet.to(device)\n",
    "            y_resnet2 = y_resnet2.to(device)\n",
    "            \n",
    "            # get predictions\n",
    "            resnet_out = model.resnet(X_resnet)\n",
    "            effnet_out = model.effnet(X_effnet)\n",
    "            resnet2_out = model.resnet2(X_resnet2)\n",
    "            \n",
    "            # compute losses\n",
    "            loss_resnet = loss_fn(resnet_out, y_resnet)\n",
    "            loss_effnet = loss_fn(effnet_out, y_effnet)\n",
    "            loss_resnet2 = loss_fn(resnet2_out, y_resnet2)\n",
    "            \n",
    "            # total loss\n",
    "            loss = (loss_resnet + loss_effnet + loss_resnet2) / 3\n",
    "            \n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 64 == 0:\n",
    "                print(f\"loss: {loss.item():>7f}\")\n",
    "        \n",
    "        # validation loop\n",
    "        model.eval()\n",
    "        test_loss, f2 = 0, 0\n",
    "        num_batches = min(len(resnet_test_loader), len(effnet_test_loader), len(resnet2_test_loader))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (X_resnet, y_resnet), (X_effnet, y_effnet), (X_resnet2, y_resnet2) in zip(\n",
    "                resnet_test_loader, effnet_test_loader, resnet2_test_loader\n",
    "            ):\n",
    "                X_resnet = X_resnet.to(device)\n",
    "                X_effnet = X_effnet.to(device)\n",
    "                X_resnet2 = X_resnet2.to(device)\n",
    "                \n",
    "                y_resnet = y_resnet.to(device)\n",
    "                y_effnet = y_effnet.to(device)\n",
    "                y_resnet2 = y_resnet2.to(device)\n",
    "                \n",
    "                # get model predictions\n",
    "                pred_resnet = model.resnet(X_resnet)\n",
    "                pred_effnet = model.effnet(X_effnet)\n",
    "                pred_resnet2 = model.resnet2(X_resnet2)\n",
    "                \n",
    "                # ensemble prediction\n",
    "                if model.ensemble_type == 'weighted':\n",
    "                    normalized_weights = F.softmax(model.weights, dim=0)\n",
    "                    pred = (\n",
    "                        normalized_weights[0] * pred_resnet + \n",
    "                        normalized_weights[1] * pred_effnet + \n",
    "                        normalized_weights[2] * pred_resnet2\n",
    "                    )\n",
    "\n",
    "                elif model.ensemble_type == 'dudani':\n",
    "                    # dudani's rule dynamic weights\n",
    "                    distances = torch.stack([\n",
    "                        -torch.max(torch.sigmoid(pred_resnet), dim=1)[0],\n",
    "                        -torch.max(torch.sigmoid(pred_effnet), dim=1)[0],\n",
    "                        -torch.max(torch.sigmoid(pred_resnet2), dim=1)[0]\n",
    "                    ], dim=1)\n",
    "\n",
    "                    d1, _ = torch.min(distances, dim=1, keepdim=True)\n",
    "                    dk, _ = torch.max(distances, dim=1, keepdim=True)\n",
    "                    \n",
    "                    dudani_weights = (dk - distances) / (dk - d1 + 1e-9)\n",
    "                    dudani_weights[distances == d1] = 1.0\n",
    "                    dudani_weights[distances == dk] = 0.0\n",
    "                    dudani_weights = dudani_weights / dudani_weights.sum(dim=1, keepdim=True)\n",
    "                    \n",
    "                    pred = (\n",
    "                        dudani_weights[:, 0].unsqueeze(1) * pred_resnet +\n",
    "                        dudani_weights[:, 1].unsqueeze(1) * pred_effnet +\n",
    "                        dudani_weights[:, 2].unsqueeze(1) * pred_resnet2\n",
    "                    )\n",
    "\n",
    "                elif model.ensemble_type == 'shepard':\n",
    "                    # shepard's rule dynamic weights\n",
    "                    distances = torch.stack([\n",
    "                        -torch.max(torch.sigmoid(pred_resnet), dim=1)[0],\n",
    "                        -torch.max(torch.sigmoid(pred_effnet), dim=1)[0],\n",
    "                        -torch.max(torch.sigmoid(pred_resnet2), dim=1)[0]\n",
    "                    ], dim=1)  # Shape: [batch_size, num_models]\n",
    "                    \n",
    "                    # shepard weights\n",
    "                    shepard_weights = torch.exp(-model.a * torch.abs(distances) ** model.b)\n",
    "                    shepard_weights = shepard_weights / shepard_weights.sum(dim=1, keepdim=True)\n",
    "                    \n",
    "                    # ensemble prediction\n",
    "                    pred = (\n",
    "                        shepard_weights[:, 0].unsqueeze(1) * pred_resnet + \n",
    "                        shepard_weights[:, 1].unsqueeze(1) * pred_effnet + \n",
    "                        shepard_weights[:, 2].unsqueeze(1) * pred_resnet2\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    pred = (pred_resnet + pred_effnet + pred_resnet2) / 3\n",
    "                \n",
    "                # compute test loss\n",
    "                test_loss += loss_fn(pred, y_resnet).item()\n",
    "                \n",
    "                # calculate f2 score\n",
    "                pred_tags = torch.sigmoid(pred).cpu().numpy() > threshold\n",
    "                true_tags = y_resnet.cpu().numpy()\n",
    "                f2 += fbeta_score(true_tags, pred_tags, beta=2, average='micro')\n",
    "        \n",
    "        test_loss /= num_batches\n",
    "        f2 /= num_batches\n",
    "        \n",
    "        print(f\"Test Error: \\n f2 score: {f2:.5f}, avg loss: {test_loss:>8f} \\n\")\n",
    "        all_loss.append(test_loss)\n",
    "\n",
    "        scheduler.step()\n",
    "        print(scheduler.get_last_lr())\n",
    "    \n",
    "    return model, all_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "epochs = 1\n",
    "threshold = 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.078989\n",
      "loss: 0.039761\n",
      "loss: 0.045638\n",
      "loss: 0.046747\n",
      "loss: 0.039083\n",
      "loss: 0.042317\n",
      "loss: 0.032731\n",
      "loss: 0.026938\n",
      "loss: 0.029724\n",
      "loss: 0.028663\n",
      "loss: 0.027427\n",
      "loss: 0.045305\n",
      "loss: 0.022390\n",
      "loss: 0.029219\n",
      "loss: 0.028084\n",
      "loss: 0.023539\n",
      "loss: 0.022054\n",
      "loss: 0.021091\n",
      "Test Error: \n",
      " f2 score: 0.97803, avg loss: 0.027023 \n",
      "\n",
      "[7.500000000000001e-05]\n"
     ]
    }
   ],
   "source": [
    "ensemble_model, loss_history = train_ensemble_model(\n",
    "    resnet_train_loader,\n",
    "    effnet_train_loader,\n",
    "    resnet2_train_loader,\n",
    "    resnet_test_loader,\n",
    "    effnet_test_loader,\n",
    "    resnet2_test_loader,\n",
    "    num_classes=num_classes,\n",
    "    epochs=epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    threshold=threshold,\n",
    "    ensemble_type='weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ensemble_model.state_dict(), \"LP_OS_ML_OS_ResNet50.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
